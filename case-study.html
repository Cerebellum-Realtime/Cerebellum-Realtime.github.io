<!doctype html>
<html lang="en" dir="ltr" class="mdx-wrapper mdx-page plugin-pages plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.2.1">
<title data-rh="true">Case Study | Cerebellum</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://cerebellum-realtime.github.io/img/cerebellum_transparent.png"><meta data-rh="true" name="twitter:image" content="https://cerebellum-realtime.github.io/img/cerebellum_transparent.png"><meta data-rh="true" property="og:url" content="https://cerebellum-realtime.github.io/case-study"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="Case Study | Cerebellum"><meta data-rh="true" name="description" content="Cerebellum Case Study"><meta data-rh="true" property="og:description" content="Cerebellum Case Study"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://cerebellum-realtime.github.io/case-study"><link data-rh="true" rel="alternate" href="https://cerebellum-realtime.github.io/case-study" hreflang="en"><link data-rh="true" rel="alternate" href="https://cerebellum-realtime.github.io/case-study" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.ff45bdb3.css">
<script src="/assets/js/runtime~main.251c8525.js" defer="defer"></script>
<script src="/assets/js/main.2ec95f51.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.png" alt="Cerebellum Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.png" alt="Cerebellum Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Cerebellum</b></a></div><div class="navbar__items navbar__items--right"><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/case-study">Case Study</a><a class="navbar__item navbar__link" href="/docs/using-cerebellum">Docs</a><a class="navbar__item navbar__link" href="/team">Team</a><a href="https://github.com/cerebellum-realtime" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><main><div class="row"><div class="sidebar"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#introduction" class="table-of-contents__link toc-highlight">Introduction</a></li><li><a href="#background-realtime" class="table-of-contents__link toc-highlight">Background: Realtime</a><ul><li><a href="#realtime-categories" class="table-of-contents__link toc-highlight">Realtime Categories</a></li><li><a href="#realtime-techniques--technologies" class="table-of-contents__link toc-highlight">Realtime Techniques &amp; Technologies</a></li><li><a href="#scaling-websocket-applications-is-not-trivial" class="table-of-contents__link toc-highlight">Scaling WebSocket Applications is Not Trivial</a></li></ul></li><li><a href="#cerebellums-niche" class="table-of-contents__link toc-highlight">Cerebellum&#39;s Niche</a></li><li><a href="#building-cerebellums-infrastructure" class="table-of-contents__link toc-highlight">Building Cerebellum’s Infrastructure</a><ul><li><a href="#establishing-a-connection-on-a-single-server" class="table-of-contents__link toc-highlight">Establishing a Connection on a Single Server</a></li><li><a href="#scaling-complexities-with-multiple-servers" class="table-of-contents__link toc-highlight">Scaling Complexities with Multiple Servers</a></li><li><a href="#persisting-data-in-a-realtime-application" class="table-of-contents__link toc-highlight">Persisting Data in a Realtime Application</a></li><li><a href="#http-endpoint" class="table-of-contents__link toc-highlight">HTTP Endpoint</a></li><li><a href="#final-architecture" class="table-of-contents__link toc-highlight">Final Architecture</a></li></ul></li><li><a href="#realtime-engineering-challenges" class="table-of-contents__link toc-highlight">Realtime Engineering Challenges</a><ul><li><a href="#sticky-sessions" class="table-of-contents__link toc-highlight">Sticky Sessions</a></li><li><a href="#connection-state-recovery" class="table-of-contents__link toc-highlight">Connection State Recovery</a></li><li><a href="#authentication" class="table-of-contents__link toc-highlight">Authentication</a></li><li><a href="#presence" class="table-of-contents__link toc-highlight">Presence</a></li></ul></li><li><a href="#load-testing" class="table-of-contents__link toc-highlight">Load Testing</a></li><li><a href="#in-the-pipeline" class="table-of-contents__link toc-highlight">In the Pipeline...</a></li></ul></div></div><div class="col max-w-7xl col--8"><article class="m-w-4xl p-4"><h1>Case Study</h1>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="introduction">Introduction<a href="#introduction" class="hash-link" aria-label="Direct link to Introduction" title="Direct link to Introduction">​</a></h2>
<p>Cerebellum is a drop-in infrastructure and library for scalable realtime applications. Whether starting from scratch or integrating an existing application, Cerebellum enables developers to move from development to fully scalable deployment in just a few simple steps.</p>
<p>Alongside our ready-made infrastructure, we offer a Software Development Kit (SDK) and a production-ready WebSocket server, empowering developers to deploy quickly and efficiently without the hassle of managing cloud platforms or connections.</p>
<figure class="image-container"><img src="/case-study/photos/Full_Infrastructure_Diagram.png" class="diagram" alt="Cerebellum Infrastructure" width="85%"><figcaption align="center">Cerebellum&#x27;s Complete Infrastructure</figcaption></figure>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="background-realtime">Background: Realtime<a href="#background-realtime" class="hash-link" aria-label="Direct link to Background: Realtime" title="Direct link to Background: Realtime">​</a></h2>
<p>Let’s take a step back to understand the concept of realtime. Realtime is the <em>instantaneous</em> exchange of data. Instantaneous in computing terms means to be <em>perceived</em> as instantaneous. This metric can vary depending on the constraints of the application, but instantaneous is commonly considered to be <a href="https://www.pubnub.com/blog/how-fast-is-realtime-human-perception-and-technology/" target="_blank" rel="noopener noreferrer">below 100-millisecond latency</a>.</p>
<p>Realtime applications are divided into two main categories, each with distinct time constraints or “deadlines” that must be met to ensure a proper response.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="realtime-categories">Realtime Categories<a href="#realtime-categories" class="hash-link" aria-label="Direct link to Realtime Categories" title="Direct link to Realtime Categories">​</a></h3>
<p><strong>Hard realtime</strong> applications demand absolute performance where timing is crucial, and deadlines <strong>must</strong> be met without exception. Missing a deadline in a hard realtime system can lead to total system failure and catastrophic consequences, often involving safety hazards or physical damage. The importance of a task is directly tied to meeting its deadline; missing it can render the task&#x27;s value null. Examples of such systems include emergency medical devices, industrial automation systems, and flight control systems.</p>
<p>In <strong>soft realtime</strong> applications, missing a deadline results in a degradation of service quality, which can negatively impact user experience and be quite frustrating. However, it does not lead to system failure or significant harm. The value of a task is somewhat correlated with meeting the deadline—if missed, the value decreases but does not become null. Examples of soft realtime systems include messaging apps, online multiplayer games, and collaborative editors. <em>Cerebellum is designed specifically for soft realtime applications.</em></p>
<div class="flex flex-row multi-image-container"><figure class="image-container flex-1 flex-grow"><img src="/case-study/photos/Hard_Realtime.png" class="diagram" alt="Hard Realtime" width="60%"><figcaption align="center">Hard Realtime</figcaption></figure><figure class="image-container flex-1 flex-grow"><img src="/case-study/photos/Soft_Realtime.png" class="diagram" alt="Soft Realtime" width="60%"><figcaption align="center">Hard Realtime</figcaption></figure></div>
<p>Before we dive deeper into Cerebellum, we need to review a few key techniques and technologies for building realtime web applications.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="realtime-techniques--technologies">Realtime Techniques &amp; Technologies<a href="#realtime-techniques--technologies" class="hash-link" aria-label="Direct link to Realtime Techniques &amp; Technologies" title="Direct link to Realtime Techniques &amp; Technologies">​</a></h3>
<p><strong>Short polling</strong> involves sending HTTP requests at intervals to check for new data. While simple to implement, it can create unnecessary network traffic and server load when no new updates are available.</p>
<figure class="image-container"><img src="/case-study/photos/ShortPolling_Diagram.png" class="diagram" alt="Short Polling" width="30%"><figcaption align="center">Short Polling</figcaption></figure>
<p><strong>Long polling</strong> improves on this by keeping the connection open until new data arrives, reducing redundant requests. However, it still requires the client to initiate each new request, which can lead to occasional synchronization issues.</p>
<figure class="image-container"><img src="/case-study/photos/LongPolling_Diagram.png" class="diagram" alt="Long Polling" width="30%"><figcaption align="center">Long Polling</figcaption></figure>
<p><strong>Server-Sent Events</strong> (SSEs) further optimize this process by maintaining an open connection where the server continuously pushes updates to the client as they become available, eliminating the need for repeated requests and minimizing latency.</p>
<figure class="image-container"><img src="/case-study/photos/SSE_Diagram.png" class="diagram" alt="Server-Sent Events" width="30%"><figcaption align="center">Server-Sent Events</figcaption></figure>
<p>While SSEs are efficient for one-way updates, they do not allow the client to send data back to the server in the same connection. This is where WebSockets excel.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="websockets">WebSockets<a href="#websockets" class="hash-link" aria-label="Direct link to WebSockets" title="Direct link to WebSockets">​</a></h4>
<p>The <strong>WebSocket</strong> protocol offers full-duplex communication over a single long-lived Transmission Control Protocol (TCP) connection. After an initial “handshake” to establish the connection, a dedicated low-latency channel is created, allowing for <em>instantaneous</em> data exchange in <em>both</em> directions.</p>
<figure class="image-container"><img src="/case-study/photos/WebSocket_Diagram1.png" class="diagram" alt="WebSocket Diagram" width="30%"><figcaption align="center">WebSocket Connection</figcaption></figure>
<p>However, WebSockets are complex to set up and manage due to their persistent connection and stateful nature. WebSockets require both browser and server-side support, but their long-standing presence means they are widely compatible across platforms. Additionally, WebSockets suffer from head-of-line blocking, where delays in one message can impact the delivery of subsequent messages.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="webtransport">WebTransport<a href="#webtransport" class="hash-link" aria-label="Direct link to WebTransport" title="Direct link to WebTransport">​</a></h4>
<p>The WebTransport API is an emerging technology that offers a promising alternative to WebSockets. WebTransport utilizes multiplexed streams and datagrams over HTTP/3 and the QUIC protocol. This setup allows multiple data streams to function independently within the same connection, reducing latency and avoiding head-of-line blocking—a problem in single-stream systems like WebSockets where delays in one packet can affect all subsequent packets. WebTransport’s capabilities make it particularly effective for handling numerous simultaneous realtime data exchanges, such as video streaming or complex online games.</p>
<p>However, WebTransport is still in development and lacks support across all browsers. It also requires server-side support, which is not yet as widely available as WebSocket support.</p>
<figure class="image-container"><img src="/case-study/photos/CommunicationComparisonChart.png" class="diagram" alt="Realtime Comparison Chart" width="60%"><figcaption align="center">Realtime Techniques &amp; Technologies</figcaption></figure>
<p>We determined that WebSockets are the most suitable for our focus and application. However, WebSockets come with distinct complexities, particularly when it comes to scaling.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="scaling-websocket-applications-is-not-trivial">Scaling WebSocket Applications is Not Trivial<a href="#scaling-websocket-applications-is-not-trivial" class="hash-link" aria-label="Direct link to Scaling WebSocket Applications is Not Trivial" title="Direct link to Scaling WebSocket Applications is Not Trivial">​</a></h3>
<p>Scaling web applications typically involves vertical scaling, horizontal scaling, or some combination thereof. Vertical scaling involves adding more power to a single server, while horizontal scaling spreads the load across multiple servers.</p>
<div class="flex justify-center video-container"><figure class="image-container p-4 flex flex-col scaling-gif justify-center items-center"><div class="flex flex-grow flex-1 bg-white items-center justify-center rounded-lg"><video src="/case-study/videos/vertical_scale_cropped.mp4" loop="" autoplay="" muted="" playsinline="" class="w-full rounded-lg"></video></div><figcaption align="center">Vertical Scaling</figcaption></figure><figure class="image-container p-4 flex flex-col scaling-gif justify-center items-center"><div class="flex flex-grow flex-1 bg-white items-center justify-center rounded-lg"><video src="/case-study/videos/horizontal_scaling_cropped.mp4" loop="" autoplay="" muted="" playsinline="" class="flex-grow w-full rounded-lg"></video></div><figcaption align="center">Horizontal Scaling</figcaption></figure></div>
<p>Scaling realtime WebSocket applications comes with an additional set of unique challenges. It’s helpful to use HTTP-based applications as a benchmark to understand these challenges.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="challenges-with-state">Challenges with State<a href="#challenges-with-state" class="hash-link" aria-label="Direct link to Challenges with State" title="Direct link to Challenges with State">​</a></h4>
<p>One of the main differences between HTTP-based applications and WebSocket applications relates to state. In an HTTP interaction, the client initiates a request to the server, which processes the request and sends back a response, after which the connection is terminated. This type of communication is considered stateless because each request is independent and doesn’t rely on information from previous interactions. Because HTTP-based applications are stateless, any server can handle any request, making horizontal scaling more straightforward.</p>
<p>WebSocket applications differ by maintaining an ongoing connection between the client and server, requiring each server to manage the session state and route messages accordingly. This continuity complicates scaling, as servers need to coordinate which clients are connected to them. Unlike HTTP, WebSockets require more infrastructure to maintain these persistent connections.</p>
<div class="flex justify-center video-container"><figure class="image-container p-4 flex flex-col scaling-gif justify-center items-center"><div class="flex flex-grow flex-1 bg-white items-center justify-center rounded-lg"><video src="/case-study/videos/client_server_cropped.mp4" loop="" autoplay="" muted="" playsinline="" class="w-full"></video></div><figcaption align="center">Single Server Managing Connection State</figcaption></figure><figure class="image-container p-4 flex flex-col scaling-gif justify-center items-center"><video src="/case-study/videos/client_server_msg_lost_cropped.mp4" loop="" autoplay="" muted="" playsinline="" class="flex-grow w-full rounded-lg"></video><figcaption align="center">Multiple Servers without Infrastructure for Connection State Management</figcaption></figure></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="challenges-with-performance">Challenges with Performance<a href="#challenges-with-performance" class="hash-link" aria-label="Direct link to Challenges with Performance" title="Direct link to Challenges with Performance">​</a></h4>
<p>Servers managing WebSocket connections face a heavier workload than those handling standard HTTP requests. WebSockets’ ongoing connections increase resource consumption, especially memory and CPU. This can lead to performance issues and a poor user experience if not properly managed.</p>
<p>Some applications add realtime features to existing servers that also handle non-realtime tasks. While simple, this &quot;tightly coupled&quot; approach introduces risks as the app scales:</p>
<ul>
<li><strong>Performance Bottlenecks:</strong> Shared resources can slow down both realtime and non-realtime tasks.</li>
<li><strong>Scaling Challenges:</strong> Realtime and non-realtime components may need to scale differently, making management harder.</li>
<li><strong>Single Point of Failure:</strong> A failure in the server affects both components, increasing downtime risks.</li>
</ul>
<p>Decoupling the realtime and non-realtime components allows each to scale independently, improving performance and reliability as the application grows.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="dedicated-realtime-infrastructure">Dedicated Realtime Infrastructure<a href="#dedicated-realtime-infrastructure" class="hash-link" aria-label="Direct link to Dedicated Realtime Infrastructure" title="Direct link to Dedicated Realtime Infrastructure">​</a></h4>
<p>Scaling WebSocket applications effectively requires specialized infrastructure. However, sourcing, configuring, and maintaining such infrastructure can be a significant burden for developers, diverting attention away from core product development. A dedicated infrastructure for realtime communication not only alleviates these challenges but also ensures that both performance and state management are optimized for the unique demands of WebSocket applications.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="cerebellums-niche">Cerebellum&#x27;s Niche<a href="#cerebellums-niche" class="hash-link" aria-label="Direct link to Cerebellum&#x27;s Niche" title="Direct link to Cerebellum&#x27;s Niche">​</a></h2>
<p>For teams with a core focus on realtime, DIY solutions like Node.js&#x27; WebSocket library or Socket.io offer complete control and flexibility over data and infrastructure. However, these solutions require significant effort to set up and maintain.</p>
<p>If realtime isn&#x27;t your core product, third-party solutions like Ably or PartyKit can simplify integration and reduce setup time. These services handle infrastructure and offer easy-to-use abstractions but provide less control over data and customization.</p>
<p>Cerebellum bridges the gap for teams seeking a balance between low effort, high flexibility, and full control over their data.</p>
<p>To help evaluate solutions, we considered several key attributes:</p>
<ul>
<li><strong>Data Persistence:</strong> Duration and method of storing messages across sessions.</li>
<li><strong>User Presence:</strong> Capability to track and report user status in real time.</li>
<li><strong>Open Source:</strong> Availability of source code for inspection and modification.</li>
<li><strong>Data Ownership:</strong> Control over the data generated and stored.</li>
<li><strong>Exactly Once Delivery:</strong> Assurance that messages are delivered exactly once.</li>
<li><strong>Auto Scaling:</strong> Ability to automatically adjust resources based on demand.</li>
<li><strong>Multi-Language Support:</strong> Compatibility with different programming languages.</li>
<li><strong>Cost:</strong> Overall expenses related to using and scaling the service.</li>
</ul>
<figure class="image-container"><img src="/case-study/photos/Product_Comparison_Chart.png" class="diagram" alt="Realtime Solution Comparison Chart" width="60%"><figcaption align="center">Comparing Solutions</figcaption></figure>
<p>*Ably stores all messages for two minutes out of the box, with an option to increase to 72 hours in their premium package. Longer data persistence requires a third-party solution.</p>
<p>Cerebellum is built for small to medium-sized development teams who want a realtime solution that handles infrastructure with strong support for data persistence, long-term storage, and an easy-to-use interface.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="building-cerebellums-infrastructure">Building Cerebellum’s Infrastructure<a href="#building-cerebellums-infrastructure" class="hash-link" aria-label="Direct link to Building Cerebellum’s Infrastructure" title="Direct link to Building Cerebellum’s Infrastructure">​</a></h2>
<p>Cerebellum was built with scaling in mind. This required provisioning servers for horizontal scaling, ensuring our architecture could maintain performance and reliability as the number of WebSocket connections increased.</p>
<p>The <a href="https://www.ibm.com/topics/cap-theorem" target="_blank" rel="noopener noreferrer">CAP theorem</a> highlights a fundamental trade-off in distributed systems: they can prioritize either availability or consistency, but not both simultaneously. Availability ensures that data requests always receive a response, even if parts of the system fail. Consistency guarantees that all clients see the same data, which can sometimes come at the expense of longer load times.</p>
<p>Since Cerebellum is designed for soft realtime applications, we prioritize availability over consistency.</p>
<p>We chose AWS as our preferred platform to host the infrastructure, due to its extensive service offerings and <a href="https://www.statista.com/chart/18819/worldwide-market-share-of-leading-cloud-infrastructure-service-providers/" target="_blank" rel="noopener noreferrer">dominant market share</a> among cloud providers.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="establishing-a-connection-on-a-single-server">Establishing a Connection on a Single Server<a href="#establishing-a-connection-on-a-single-server" class="hash-link" aria-label="Direct link to Establishing a Connection on a Single Server" title="Direct link to Establishing a Connection on a Single Server">​</a></h3>
<p>We initially built our infrastructure with a single WebSocket server, allowing us to simplify development and focus on creating a stable realtime communication library.</p>
<figure class="image-container"><img src="/case-study/photos/buildingCB_OneServer.png" class="diagram" alt="Illustration of clients connecting to a single server" width="35%"><figcaption align="center">Single-Server Connections</figcaption></figure>
<p>We hosted our WebSocket application on a server with 0.25 vCPU and 0.5 GB of RAM. When we exceeded 4,000 concurrent users, CPU utilization was nearing 70%, which is AWS’s recommended threshold for scaling. Beyond this point, server response times could increase, and the risk of crashes becomes higher without additional resources. Moreover, relying on a single server introduces a single point of failure.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="scaling-complexities-with-multiple-servers">Scaling Complexities with Multiple Servers<a href="#scaling-complexities-with-multiple-servers" class="hash-link" aria-label="Direct link to Scaling Complexities with Multiple Servers" title="Direct link to Scaling Complexities with Multiple Servers">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="scalable-servers">Scalable Servers<a href="#scalable-servers" class="hash-link" aria-label="Direct link to Scalable Servers" title="Direct link to Scalable Servers">​</a></h4>
<p>We used AWS Elastic Container Service (ECS) with AWS Fargate to set up our infrastructure for horizontal scaling. Containers are lightweight, portable units that package an application and its dependencies. These containers are created from images, which are snapshots of the application environment, including the code, libraries, and system settings.</p>
<p>ECS is an orchestrator—it manages the number of containers running at any given time. ECS monitors server load and decides when to scale up or down accordingly. Fargate is a compute engine that eliminates the need to provision and manage servers by creating serverless containers on demand. It allows us to define a Docker or Elastic Container Registry image (our WebSocket server by default) and creates a container with a pre-specified operating system.</p>
<figure class="image-container"><img src="/case-study/photos/buildingCB_ECSCluster.png" class="diagram" alt="Illustration of two clients connecting to a cluster of servers" width="45%"><figcaption align="center">Multi-Server Connections</figcaption></figure>
<p>While our infrastructure could now automatically scale based on user load, users connected to different servers couldn&#x27;t communicate with each other. Each server maintained its own isolated state and connection data. As a result, a user connected to one server wouldn&#x27;t be able to reach a user connected to a different server.</p>
<p>We needed a way for data to allow data flow and consistency between our servers. We implemented a pub/sub to facilitate this cross-server communication.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="pubsub">Pub/Sub<a href="#pubsub" class="hash-link" aria-label="Direct link to Pub/Sub" title="Direct link to Pub/Sub">​</a></h4>
<p>Publish/Subscribe (Pub/Sub) is a messaging pattern used in distributed systems to facilitate communication between different components. For context around this discussion, we’ll define some key terms related to the pub/sub model:</p>
<ul>
<li><strong>Channels</strong> (also known as &quot;rooms&quot; or &quot;topics&quot;) are communication hubs where messages are exchanged between publishers and subscribers.</li>
<li><strong>Subscribers</strong> are users or systems that receive notifications when a message is sent to a channel they follow.</li>
<li><strong>Publishers</strong> are users or systems that send messages to channels.</li>
</ul>
<p>In the pub/sub model, publishers and subscribers are decoupled. Publishers can send messages to channels without needing to know who the subscribers are, and subscribers receive messages without knowing who the publishers are.</p>
<p>By implementing a pub/sub system, when a user sends a message to a server, it is received by the pub/sub system and forwarded to all subscribers of that channel, regardless of which server they are connected to. This ensures that all users receive the same information in real time, overcoming the challenges of server isolation and ensuring consistent message delivery across multiple servers.</p>
<figure class="image-container"><video src="/case-study/videos/ChannelsPubSub.mp4" loop="" autoplay="" muted="" playsinline="" class="rounded-lg"></video><figcaption align="center">Illustration of a User Posting a Message to a Channel</figcaption></figure>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="redis-streams-as-our-pubsub-system">Redis Streams as Our Pub/Sub System<a href="#redis-streams-as-our-pubsub-system" class="hash-link" aria-label="Direct link to Redis Streams as Our Pub/Sub System" title="Direct link to Redis Streams as Our Pub/Sub System">​</a></h4>
<p>For our pub/sub system, we used AWS ElastiCache for Redis, specifically utilizing Redis Streams. While Redis is often known for its key/value cache functionality, it also offers powerful features for building robust pub/sub systems.</p>
<p>Redis Streams provides an append-only log data structure that supports more complex pub/sub scenarios. Key advantages include:</p>
<ul>
<li><strong>Persistence:</strong> Messages in Redis Streams can be persisted, enabling replay and recovery, which is crucial for maintaining the connection state in realtime applications (a key requirement which we will discuss in detail in the <a href="#realtime-engineering-challenges">Realtime Engineering Challenges</a> section).</li>
<li><strong>Backpressure Handling:</strong> Streams allow servers to regulate the rate of message consumption, preventing overload by controlling the flow of incoming messages.</li>
</ul>
<p>We selected Redis Streams due to the high availability and low latency provided by AWS ElastiCache.</p>
<p>In our Redis Streams implementation, the message flow differs slightly from traditional pub/sub systems. When a message is published, it is appended to a Redis Stream associated with a specific channel or topic. Each message is stored with a unique ID, ensuring persistence. Servers act as consumers, reading from these streams at their own pace and capacity. After retrieving messages, servers forward them to clients subscribed to the respective channels. This retains the core principles of a traditional pub/sub while also enabling data persistence.</p>
<figure class="image-container"><video src="/case-study/videos/Redis_Streams.mp4" loop="" autoplay="" muted="" playsinline="" class="rounded-lg"></video><figcaption align="center">Illustration of Servers Reading a New Message from Redis Streams</figcaption></figure>
<p>With our Redis Streams-based pub/sub system in place, we had to establish a single, secure public entry point while balancing load across multiple servers.</p>
<figure class="image-container"><img src="/case-study/photos/buildingCB_Elasticache.png" class="diagram" alt="Illustration of multiple clients connecting to a cluster of servers using Redis Streams as a pub/sub system" width="60%"><figcaption align="center">Multi-Server Connections with Redis Streams</figcaption></figure>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="balancing-the-load-distribution">Balancing the Load Distribution<a href="#balancing-the-load-distribution" class="hash-link" aria-label="Direct link to Balancing the Load Distribution" title="Direct link to Balancing the Load Distribution">​</a></h4>
<p>Realtime applications require high availability and fault tolerance to ensure seamless user experiences, even during partial system failures. We use an Application Load Balancer (ALB) to distribute incoming traffic across multiple servers to achieve this. The ALB prevents any server from becoming overwhelmed and enhances overall performance and reliability.</p>
<p>We considered a few options for routing traffic:</p>
<ul>
<li><strong>Round Robin:</strong> Distributes each request sequentially to the next server. This method works well when traffic is uniform and servers have similar processing power.</li>
<li><strong>Least Outstanding Requests:</strong> Routes traffic to the server with the fewest active connections. This is ideal when request processing times vary and servers have different capabilities.</li>
</ul>
<p>Since our infrastructure scales by duplicating containers with identical processing power, we initially considered Round Robin. However, we cannot anticipate uniform traffic in the realtime applications. Additionally, when new servers are spun up, we need to route traffic more heavily to them to utilize their increased capacity. Therefore, Least Outstanding Requests was our top choice to ensure a more balanced load across servers.</p>
<p>In addition to balancing load, the ALB provides other key benefits:</p>
<ul>
<li><strong>Health Checks</strong>: The ALB tracks which servers are healthy/unhealthy and re-routes traffic accordingly.</li>
<li><strong>SSL/TLS Encryptions</strong>: The ALB enforces encryption to protect data between client and server.</li>
</ul>
<p>By handling these tasks, the ALB solved a crucial part of our infrastructure needs, ensuring the stability and security of our realtime applications while managing server load.</p>
<figure class="image-container"><img src="/case-study/photos/buildingCB_LoadBalancer.png" class="diagram" alt="Illustration of a load balancer routing traffic to multiple servers" width="60%"><figcaption align="center">Cerebellum&#x27;s Infrastructure with an Application Load Balancer</figcaption></figure>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="persisting-data-in-a-realtime-application">Persisting Data in a Realtime Application<a href="#persisting-data-in-a-realtime-application" class="hash-link" aria-label="Direct link to Persisting Data in a Realtime Application" title="Direct link to Persisting Data in a Realtime Application">​</a></h3>
<p>At this stage, our architecture successfully provided realtime scaling and communication, but we recognized a major limitation in the need for historical data access. This is vital for various realtime applications, including:</p>
<ul>
<li><strong>Collaborative Editors:</strong> Applications like Google Docs need to maintain past revisions.</li>
<li><strong>Video Conferencing:</strong> Services like Zoom provide video recording features.</li>
<li><strong>Communication Apps:</strong> Platforms like Slack require persistent message history.</li>
</ul>
<figure class="image-container"><video src="/case-study/videos/MessageHistory.mp4" loop="" autoplay="" muted="" playsinline="" class="rounded-lg"></video></figure>
<figcaption align="center">Illustration of a Communication App without Data Persistence</figcaption>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="choosing-the-right-database-for-realtime-applications">Choosing the Right Database for Realtime Applications<a href="#choosing-the-right-database-for-realtime-applications" class="hash-link" aria-label="Direct link to Choosing the Right Database for Realtime Applications" title="Direct link to Choosing the Right Database for Realtime Applications">​</a></h4>
<p>Considerations when selecting a database for realtime applications were scalability, low latency, high throughput, and flexibility—specifically regarding dynamic data structures. Because these were our major considerations, we ruled out SQL databases, which are more rigid in structure and require complex partitioning when scaling.</p>
<p>With these in mind, we chose AWS DynamoDB. DynamoDB’s ability to distribute data across multiple servers allows for smooth expansion as user bases grow, ensuring that Cerebellum-powered applications remain responsive even under heavy traffic. Its optimized read and write operations are crucial for handling the high throughput required in realtime scenarios. Moreover, DynamoDB’s flexible schema supports the dynamic and evolving data models typical in realtime application development. For these reasons, DynamoDB offers an excellent blend of scalability, performance, and adaptability, making it well-suited to our needs.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="availability-vs-consistency">Availability vs. Consistency<a href="#availability-vs-consistency" class="hash-link" aria-label="Direct link to Availability vs. Consistency" title="Direct link to Availability vs. Consistency">​</a></h4>
<p>With our database solution in place, we were faced with balancing availability and consistency in our realtime data interactions. This balance is essential for maintaining the responsiveness expected in realtime applications while ensuring data integrity.</p>
<p>Direct communication between servers and databases in a realtime environment is straightforward and ensures strong consistency, but it also poses several issues:</p>
<ul>
<li><strong>Increased Latency:</strong> Each database operation requires a round trip between the server and the database, adding delays that can be detrimental in realtime applications where milliseconds matter.</li>
<li><strong>Connection Overhead:</strong> Maintaining numerous open database connections for each user session can strain server and database resources, leading to inefficiencies.</li>
<li><strong>Database Bottlenecks:</strong> High-volume realtime applications can overwhelm databases with rapid read/write requests, potentially causing performance degradation or system failures.</li>
</ul>
<figure class="image-container"><video src="/case-study/videos/Writing_to_DB.mp4" loop="" autoplay="" muted="" playsinline="" class="rounded-lg"></video><figcaption align="center">Strong Consistency System: Writing Data to a Database</figcaption></figure>
<p>While this method ensures data consistency, the resulting latency and resource strain make it less suited for realtime applications where immediate responsiveness is optimal.</p>
<p>We implemented a queue system between the servers and the database, using AWS Simple Queue Services and AWS Lambda. This approach offers several key benefits:</p>
<ul>
<li><strong>Decoupling:</strong> The queue buffers operations, letting the realtime server respond to clients without waiting for the database, ensuring quick responses.</li>
<li><strong>Responsiveness:</strong> Servers can process and acknowledge client requests promptly, meeting realtime app expectations.</li>
<li><strong>Managed Load:</strong> The queue controls data flow to the database, preventing performance issues from sudden write bursts.</li>
<li><strong>Resilience:</strong> If the database fails temporarily, the queue holds data until it&#x27;s ready, minimizing data loss risk.</li>
<li><strong>Eventual Consistency:</strong> While not immediately consistent, the queue ensures all data is eventually processed, preserving integrity.</li>
</ul>
<figure class="image-container"><video src="/case-study/videos/Writing_to_Queue.mp4" loop="" autoplay="" muted="" playsinline="" class="rounded-lg"></video><figcaption align="center">Strong Availability System: Writing Data to a Queue</figcaption></figure>
<p>When a client sends data to Cerebellum servers, the server will immediately timestamp the message and send it to the queue. The server continues to process the request without waiting for a confirmation from the database. When the message reaches the front of the queue, a serverless function will process the message and save it to the database. If the database write fails, the queue can retry the operation or save the data in the dead-letter queue—a special queue where undeliverable or failed messages are sent, allowing developers to analyze and fix issues. This ensures data is not lost.</p>
<figure class="image-container"><img src="/case-study/photos/buildingCB_DB_and_Queue.png" class="diagram" alt="Illustration of saving data to a database using a queue" width="60%"><figcaption align="center">Cerebellum&#x27;s Infrastructure Enabling Availability with Eventual Consistency</figcaption></figure>
<p>This approach allowed us to prioritize availability while maintaining eventual consistency. Although there is a slight delay in data persistence, this trade-off is minor compared to the performance gains. Overall, DynamoDB’s fast, flexible nature proved to be an excellent choice for handling realtime workloads, even under heavy traffic. However, as data grows over time, the cost of storing vast amounts of information in DynamoDB increases significantly. To address this, we implemented a long-term solution for managing historical data without sacrificing performance or inflating costs.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="archiving-data">Archiving Data<a href="#archiving-data" class="hash-link" aria-label="Direct link to Archiving Data" title="Direct link to Archiving Data">​</a></h4>
<p>As DynamoDB tables expand, older data will likely be accessed infrequently or not at all. Leaving this data in DynamoDB can add unnecessary costs to the developer.</p>
<blockquote>
<p>Let’s consider a realtime communication platform, similar to Slack. To set up this example, we make the following assumptions:</p>
<ul>
<li>100,000 users per day</li>
<li>20 messages per user per day</li>
<li>200 bytes per message</li>
<li>Archive any data older than 1 year</li>
</ul>
<p>This means that in a 30 day month, we would have:</p>
<p>100,000 users/day * 20 messages * 200 bytes/message * 30 days = 12 GB per month</p>
<p>AWS charges $0.25 per GB per month for DynamoDB. In our example, that would result in:</p>
<p>$0.25 per GB-month * 12 GB = $3 per month</p>
<p>If every message was left in DynamoDB indefinitely, it would result in an <em>additional</em> $3 per month. Over 5 years, the AWS bill for storage alone would roughly cost:</p>
<p>$3 + $6 + $9 + … + $180 = $5,490</p>
<p>If we were to archive all messages older than 1 year, we would get a max storage per year of:</p>
<p>12 GB * 12 months = 144 GB/month</p>
<p>Paying for this across 5 years, the DynamoDB bill would be:</p>
<p>144 GB * 60 months * $0.25 per GB-month = $2,160</p>
<p>If we were archiving every month, this would be ~12GB per month. The cost of storing data in an S3 bucket is $0.023 per GB per month. This means that 1 month of storage in the S3 bucket will cost:</p>
<p>12 GB * $0.023 per GB-month = $0.28</p>
<p>As a result, this storage cost for the S3 bucket over 5 years will be:</p>
<p>$0.28 + $0.56 + $0.84 + … + $16.80 = $512.40</p>
<p>That means the total spent across 5 years would be:</p>
<p>$2,160 + $512.40 = $2,672.40</p>
<p>The cost savings from archiving data would be $2,817.60.</p>
</blockquote>
<p>It is important to remove data that is not being used in DynamoDB to save on costs in the long term. A cron job will trigger a Lambda function once per week. This Lambda will retrieve data from DynamoDB, save it as one JSON file to an AWS S3 bucket, and remove it from the DynamoDB table. The developer can define the age that data should be archived within the Lambda function.</p>
<figure class="image-container"><img src="/case-study/photos/buildingCB_ArchivingData.png" class="diagram" alt="Illustration of a cron job archiving data from DynamoDB to S3" width="60%"><figcaption align="center">Cerebellum&#x27;s Infrastructure Enabling Data Archiving</figcaption></figure>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="http-endpoint">HTTP Endpoint<a href="#http-endpoint" class="hash-link" aria-label="Direct link to HTTP Endpoint" title="Direct link to HTTP Endpoint">​</a></h3>
<p>Our servers could now manage both WebSocket connections and HTTP traffic, which includes messages being published from the developer&#x27;s backend. However, our servers were still <a href="#challenges-with-performance">tightly coupled</a>.</p>
<p>We implemented a dedicated gateway for HTTP traffic using AWS API Gateway to decouple our servers and preserve performance.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="implementation-of-api-gateway-and-aws-lambda">Implementation of API Gateway and AWS Lambda<a href="#implementation-of-api-gateway-and-aws-lambda" class="hash-link" aria-label="Direct link to Implementation of API Gateway and AWS Lambda" title="Direct link to Implementation of API Gateway and AWS Lambda">​</a></h4>
<p>AWS API Gateway is the entry point for HTTP traffic, efficiently managing API requests and routing them to the appropriate backend services. It automatically scales to handle varying traffic loads, ensuring that HTTP traffic does not interfere with WebSocket connections. Additionally, API Gateway provides built-in features such as throttling and monitoring capabilities to ensure our HTTP endpoints remain performant.</p>
<p>AWS Lambda complements the API Gateway by enabling serverless execution of code in response to HTTP GET and POST requests. This allows us to handle various types of HTTP requests without the need to manage server infrastructure. Lambda&#x27;s dynamic scalability ensures that our system adapts to changing load conditions while maintaining cost efficiency.</p>
<figure class="image-container"><img src="/case-study/photos/buildingCB_APIGateway.png" class="diagram" alt="Illustration showing an API gateway with a lambda function" width="60%"><figcaption align="center">Cerebellum&#x27;s Infrastructure Including a Dedicated HTTP Gateway</figcaption></figure>
<p>The addition of HTTP endpoints alongside WebSocket connections expands the functionality and flexibility of our system. Key use cases for HTTP endpoints:</p>
<ul>
<li><strong>Data Retrieval:</strong> Use HTTP GET requests to fetch specific data or initialize application states without needing a persistent WebSocket connection.</li>
<li><strong>Message Posting:</strong> HTTP POST requests allow stateless data submissions like form entries or file uploads when realtime communication isn&#x27;t needed.</li>
<li><strong>Integration Opportunities:</strong> API Gateway endpoints enable seamless integration with third-party services, allowing external systems to push notifications or updates to our platform.</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="integration-with-dynamodb-and-other-services">Integration with DynamoDB and Other Services<a href="#integration-with-dynamodb-and-other-services" class="hash-link" aria-label="Direct link to Integration with DynamoDB and Other Services" title="Direct link to Integration with DynamoDB and Other Services">​</a></h4>
<p>Modern applications frequently interact with diverse systems and services, often across various languages and frameworks. REST APIs make this integration straightforward, using standard HTTP methods (GET, POST) and widely supported data formats (JSON). This approach simplifies connecting our DynamoDB database and servers with other services, ensuring smoother and more efficient data interactions.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="final-architecture">Final Architecture<a href="#final-architecture" class="hash-link" aria-label="Direct link to Final Architecture" title="Direct link to Final Architecture">​</a></h3>
<figure class="image-container"><img src="/case-study/photos/Full_Infrastructure_Diagram.png" class="diagram" alt="Cerebellum Final Infrastructure" width="85%"><figcaption align="center">Cerebellum&#x27;s Complete Infrastructure</figcaption></figure>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="realtime-engineering-challenges">Realtime Engineering Challenges<a href="#realtime-engineering-challenges" class="hash-link" aria-label="Direct link to Realtime Engineering Challenges" title="Direct link to Realtime Engineering Challenges">​</a></h2>
<p>We had a fully formed architecture by this point, but we still needed to handle some of the common realtime application challenges.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="sticky-sessions">Sticky Sessions<a href="#sticky-sessions" class="hash-link" aria-label="Direct link to Sticky Sessions" title="Direct link to Sticky Sessions">​</a></h3>
<p>Our WebSocket server uses Socket.io to initialize session connections, where a session is defined as a persistent WebSocket connection between the client and the server. The process of initializing a session connection is as follows:</p>
<ol>
<li>The client sends an HTTP GET request to the server with `transport=polling` in its query parameters.</li>
<li>The server responds with a session ID, an array of possible transport upgrades, and other connection-related information.<!-- -->
<ol>
<li>The session ID is used by the server to identify the client and manage the connection.</li>
<li>The list of upgrades typically includes WebSocket as the more efficient and preferred transport method.</li>
</ol>
</li>
<li>The client will then attempt to set up HTTP long-polling as a default first option.</li>
<li>The client will then attempt to upgrade the connection to a WebSocket connection by making a GET request with `transport=websocket` in the query parameters.</li>
</ol>
<figure class="image-container"><img src="/case-study/photos/WebSocket_Diagram.png" class="diagram" alt="WebSocket Connection Handshake" width="25%"><figcaption align="center">WebSocket Connection Detailed Illustration</figcaption></figure>
<p>With only one container running, this handshake process can occur without complications. A potential problem arises when we introduce a second container and a load balancer. Due to the multiple round-trip nature of establishing a WebSocket connection, a user may be routed to a container that did not create the ID and thus will not recognize it.</p>
<figure class="image-container"><video src="/case-study/videos/StickySession_Bad.mp4" loop="" autoplay="" muted="" playsinline="" class="rounded-lg"></video><figcaption align="center">Failed WebSocket Connection to a Multi-Server Application without Sticky Sessions</figcaption></figure>
<p>To solve this problem, we implemented “sticky sessions” by generating a cookie with the AWS load balancer and attaching it to each client request. Each subsequent request will receive a cookie in the response and include that cookie value in its request header. The load balancer will forward each request with a recognized cookie to the same server that initially handled it, bypassing the default algorithm. This ensures that the WebSocket connection is created between the associated server and the client.</p>
<figure class="image-container"><video src="/case-study/videos/StickySession_Good.mp4" loop="" autoplay="" muted="" playsinline="" class="rounded-lg"></video><figcaption align="center">Successful WebSocket Connection to a Multi-Server Application with Sticky Sessions Enabled</figcaption></figure>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="connection-state-recovery">Connection State Recovery<a href="#connection-state-recovery" class="hash-link" aria-label="Direct link to Connection State Recovery" title="Direct link to Connection State Recovery">​</a></h3>
<p>Users can momentarily disconnect from a server for several reasons—some common occurrences are temporary network outages or transferring from WiFi to cellular data. During this disconnection period, the user is not able to send, receive, or display the current state.</p>
<p>Leveraging our Redis ElastiCache, we provide connection state recovery. This enables users who unexpectedly disconnect to automatically return to the same WebSocket connection, restoring their session state and avoiding re-authentication (outlined in the next section).</p>
<p>In practice, when the client detects a lost connection with the server, it will try to store the last received message ID. No new data can be received during the disconnection period. Upon reconnection, the ALB will redirect the client to the same server via sticky sessions. The server will recognize the WebSocket session ID and attempt to restore the state by retrieving all missed messages from the Redis ElastiCache using Redis Streams. The messages missed between the last acknowledged message ID and the current one are fetched and delivered to the client, ensuring the state is restored.</p>
<figure class="image-container"><video src="/case-study/videos/Connection_State_Recovery.mp4" loop="" autoplay="" muted="" playsinline="" class="rounded-lg"></video><figcaption align="center">Connection State Recovery</figcaption></figure>
<p>An added benefit of this process is that upon disconnection, the client will also store any messages that have failed to send. Upon recovery, it will immediately send all buffered messages to the server.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="authentication">Authentication<a href="#authentication" class="hash-link" aria-label="Direct link to Authentication" title="Direct link to Authentication">​</a></h3>
<p>In HTTP, it&#x27;s easy to handle authentication because you can send credentials like tokens with every request. With WebSockets, once the connection is established during the initial handshake, you can’t modify headers or send additional authentication data. This makes it difficult to manage security throughout the session since there&#x27;s no built-in way to verify the user after the connection is open. To address this for Cerebellum’s WebSocket servers, we implemented token-based authentication to ensure that connections remain secure and properly authenticated throughout their duration.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="token-based-authentication">Token-Based Authentication<a href="#token-based-authentication" class="hash-link" aria-label="Direct link to Token-Based Authentication" title="Direct link to Token-Based Authentication">​</a></h4>
<p>A unique API key is generated with AWS Secrets when the servers are first created using our CLI. This API key is injected into every WebSocket server as an environment variable and safely retrievable in your AWS Secrets page. The API key should then be included as an environment variable on your login server.</p>
<p>We recommend using Cerebellum SDK to generate a short-lived token using your API key upon user authentication. This process ensures that the API key remains secure on your login servers and is not exposed to clients or external parties.</p>
<p>Cerebellum takes the following steps to secure its servers:</p>
<ol>
<li><strong>Token Generation:</strong><br>
<!-- -->After a user logs in, the SDK generates a short-lived token tied to your API key. This token has a set expiration time to minimize misuse.</li>
<li><strong>Client Authentication:</strong><br>
<!-- -->When opening a WebSocket connection, the client includes the token in the first message as a temporary credential for user authentication.</li>
<li><strong>Token Verification:</strong><br>
<!-- -->The WebSocket server verifies the token using the API key stored in an environment variable, without needing to query the main database, boosting performance and scalability.</li>
<li><strong>Handling Authentication Failures:</strong><br>
<!-- -->If the token is missing or invalid, the user is denied the connection, preventing unauthorized access and helping protect against DDoS attacks.</li>
</ol>
<div class="flex justify-center video-container"><figure class="image-container p-4 flex flex-col scaling-gif justify-center items-center"><div class="flex flex-grow flex-1 bg-white items-center justify-center rounded-lg"><video src="/case-study/videos/auth_bad_cropped.mp4" loop="" autoplay="" muted="" playsinline="" class="w-full rounded-lg"></video></div><figcaption align="center">Failed Attempt to Connect</figcaption></figure><figure class="image-container p-4 flex flex-col scaling-gif justify-center items-center"><div class="flex flex-grow flex-1 bg-white items-center justify-center rounded-lg"><video src="/case-study/videos/auth_good_cropped.mp4" loop="" autoplay="" muted="" playsinline="" class="flex-grow w-full rounded-lg"></video></div><figcaption align="center">Successful Attempt to Connect</figcaption></figure></div>
<p>By implementing this token-based authentication solution, the WebSocket servers can manage connections securely and efficiently while maintaining high performance and scalability. This approach protects the integrity of the server and ensures that only authorized users can interact with your applications.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="presence">Presence<a href="#presence" class="hash-link" aria-label="Direct link to Presence" title="Direct link to Presence">​</a></h3>
<p>In collaborative and multiplayer realtime applications, knowing who else is in the same channel or workspace is a key feature. Presence allows users to see who is active, what they’re doing, and where they’re working within the document.</p>
<p>Initially, we implemented presence using a traditional pub/sub paradigm, which allowed users to broadcast their presence to others in the same channel. However, this approach had limitations. New users joining a channel could not see who was already present, leading to a lack of awareness and coordination among users. To overcome this, we needed a solution that could effectively manage and synchronize presence information across all users and servers.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="utilizing-elasticache-for-presence">Utilizing ElastiCache for Presence<a href="#utilizing-elasticache-for-presence" class="hash-link" aria-label="Direct link to Utilizing ElastiCache for Presence" title="Direct link to Utilizing ElastiCache for Presence">​</a></h4>
<p>ElastiCache with Redis OSS is an ideal solution for managing presence information in realtime applications due to its exceptional performance and low latency. Redis OSS provides an in-memory data store that supports ultra-fast data retrieval and updates, which are essential for maintaining realtime presence status. Given that Redis was already integrated into our infrastructure for the pub/sub mechanism, extending its use to handle presence data was a natural choice. Its ability to efficiently manage rapid read/write operations makes it perfect for scenarios where user presence is frequently updated. Redis’ immediate consistency ensures that presence information is always current, allowing users to experience realtime changes without delay.</p>
<p>By leveraging Redis as our single source for presence information, we can synchronize presence data across all servers. When a user joins, leaves, or updates their presence information, the changes are immediately reflected in Redis, which is accessible by all servers in the cluster. This update is then broadcasted via the pub/sub system, notifying all users subscribed to that presence channel, and providing a consistent source of presence information for all servers.</p>
<figure class="image-container"><video src="/case-study/videos/Presence.mp4" loop="" autoplay="" muted="" playsinline="" class="rounded-lg"></video><figcaption align="center">Realtime User Presence</figcaption></figure>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="how-to-handle-disconnections">How to Handle Disconnections<a href="#how-to-handle-disconnections" class="hash-link" aria-label="Direct link to How to Handle Disconnections" title="Direct link to How to Handle Disconnections">​</a></h4>
<p>A key challenge in building presence functionality is managing user disconnections. When a client disconnects, the server must notify other users in the presence channels, as the client can no longer update its status. This prevents stale data in the Redis cache and ensures presence information stays current.</p>
<figure class="image-container"><video src="/case-study/videos/Presence_Disconnection_Bad.mp4" loop="" autoplay="" muted="" playsinline="" class="rounded-lg"></video><figcaption align="center">User Loses Connection but Presence is not Updated</figcaption></figure>
<p>To address this, we assign a unique ID to each client connected to a server. This ID is stored in Redis along with a list of all that user’s presence channels. When a disconnection event is detected, the server automatically iterates through the list of that user’s presence channels and notifies the corresponding presence channel that the user has left. Lastly, the server removes the user’s presence information from the Redis cache to ensure it always has the most up-to-date information for everyone who joins.</p>
<figure class="image-container"><video src="/case-study/videos/Presence_Disconnection.mp4" loop="" autoplay="" muted="" playsinline="" class="rounded-lg"></video><figcaption align="center">User Loses Connection and Presence is Successfully Updated</figcaption></figure>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="load-testing">Load Testing<a href="#load-testing" class="hash-link" aria-label="Direct link to Load Testing" title="Direct link to Load Testing">​</a></h2>
<p>Our primary load-testing strategy was focused on determining how many concurrent users a server could handle. To test this, we spun up one Cerebellum WebSocket server on an AWS Fargate container and ran an Artillery test on our cloud infrastructure.</p>
<p>One approach when auto-scaling in ECS is to scale horizontally when the CPU or memory reaches a certain percentage. <a href="https://docs.aws.amazon.com/autoscaling/plans/userguide/gs-configure-scaling-plan.html#:~:text=For%20example%2C%20the%20scaling%20plan,a%20different%20metric%2C%20or%20both." target="_blank" rel="noopener noreferrer">AWS recommends</a> scaling out at 40% to optimize for performance, 70% for cost, or 50% for a balanced optimization. Per this recommendation, we chose 50% as the default for high performance and reasonable cost efficiency.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="terminology">Terminology<a href="#terminology" class="hash-link" aria-label="Direct link to Terminology" title="Direct link to Terminology">​</a></h4>
<ul>
<li><strong>Max:</strong> Maximum computing resources allocated.</li>
<li><strong>Baseline:</strong> Percent utilization on the Fargate container immediately before the test.</li>
<li><strong>Peak:</strong> Percent utilization on the Fargate container at peak usage during the test.</li>
<li><strong>Difference:</strong> Difference between baseline and peak.</li>
<li><strong>Idle user:</strong> A user that connects to the server via WebSockets and does nothing</li>
<li><strong>Active users:</strong> A user that connects to the server via WebSockets and posts messages to a channel</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="1-limit-of-concurrent-idle-users">1) Limit of Concurrent Idle Users<a href="#1-limit-of-concurrent-idle-users" class="hash-link" aria-label="Direct link to 1) Limit of Concurrent Idle Users" title="Direct link to 1) Limit of Concurrent Idle Users">​</a></h4>
<ul>
<li>Created 1,000 idle users over 120 seconds</li>
<li>Recorded Peak CPU and Memory usage</li>
</ul>
<p>Results:</p>
<figure class="image-container"><img src="/case-study/photos/load_test_idle_user.png" class="diagram" alt="Load testing diagram for idle users" width="70%"><figcaption align="center">Load Testing Results for Idle Users</figcaption></figure>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="2-limit-of-concurrent-active-users">2) Limit of Concurrent Active Users<a href="#2-limit-of-concurrent-active-users" class="hash-link" aria-label="Direct link to 2) Limit of Concurrent Active Users" title="Direct link to 2) Limit of Concurrent Active Users">​</a></h4>
<ul>
<li>Created 1,000 active users over 120 seconds</li>
<li>Recorded Peak CPU and Memory usage</li>
</ul>
<p>Results:</p>
<figure class="image-container"><img src="/case-study/photos/load_test_active.png" class="diagram" alt="Load testing for active users" width="70%"><figcaption align="center">Load Testing Results for Active Users</figcaption></figure>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="calculations">Calculations<a href="#calculations" class="hash-link" aria-label="Direct link to Calculations" title="Direct link to Calculations">​</a></h4>
<p>The limiting factor causing a container to scale is the CPU usage recorded in the idle users test. Assuming a linear relationship, we extrapolated the total number of users that trigger auto-scaling.</p>
<blockquote>
<p>Baseline (%) + ( Difference (%) * Scaling Factor ) = Scaling Limit (%)</p>
<p>0.8% + (11.6% * Scaling Factor) = 50% =&gt; Scaling Factor ≈ 4.24</p>
</blockquote>
<p>Therefore, if we multiply the number of users at peak by the scaling factor, we can estimate how many concurrent users the container can handle before needing to scale.</p>
<blockquote>
<p>1,000 * 4.24 = 4,240 users</p>
</blockquote>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">​</a></h4>
<p>At 0.25 vCPU and 0.5 GB memory, Cerebellum’s WebSocket servers will comfortably accommodate 4,240 users before auto-scaling.</p>
<p>*These tests are not optimized to test the maximum load that could be placed on our Redis cache. Testing the Redis more extensively would include subscribing and adding presence for multiple users to one channel and testing the strain of the fanning out data and presence across that channel. This is a consideration for future load testing.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="in-the-pipeline">In the Pipeline...<a href="#in-the-pipeline" class="hash-link" aria-label="Direct link to In the Pipeline..." title="Direct link to In the Pipeline...">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="archived-message-retrieval">Archived Message Retrieval<a href="#archived-message-retrieval" class="hash-link" aria-label="Direct link to Archived Message Retrieval" title="Direct link to Archived Message Retrieval">​</a></h4>
<p>We’ve implemented automated message archiving to reduce costs by moving older data from DynamoDB to S3. While retrieval is supported, our WebSocket server doesn’t yet automate this. Developers currently handle it manually.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="rate-limiting">Rate Limiting<a href="#rate-limiting" class="hash-link" aria-label="Direct link to Rate Limiting" title="Direct link to Rate Limiting">​</a></h4>
<p>In building our WebSocket infrastructure with an Application Load Balancer (ALB), we focused on scalability and ease of integration. The ALB effectively manages WebSocket connections, ensuring high availability and fault tolerance, though it lacks built-in rate-limiting capabilities—an important consideration for protecting servers and ensuring fair usage.</p>
<p>Our current setup doesn’t impose rate limits on incoming WebSocket connections, leaving this aspect to be managed by external solutions or client-side throttling. While API Gateway and AWS WAF offer rate-limiting features, they introduce performance trade-offs and a need for careful cost-benefit analysis due to the complexity of configuring these services for WebSocket workloads.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="elasticache-load-testing-and-failover">ElastiCache: Load Testing and Failover<a href="#elasticache-load-testing-and-failover" class="hash-link" aria-label="Direct link to ElastiCache: Load Testing and Failover" title="Direct link to ElastiCache: Load Testing and Failover">​</a></h4>
<p>We have not yet tested the physical limit of our ElastiCache. Load testing should be performed by testing channel user limit and presence to determine this limit.</p>
<p>Additionally, this single ElastiCache represents a single point of failure. Our infrastructure would benefit from designating a fallback ElastiCache in case our active ElastiCache crashes.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="cloud-agnostic-offering">Cloud-Agnostic Offering<a href="#cloud-agnostic-offering" class="hash-link" aria-label="Direct link to Cloud-Agnostic Offering" title="Direct link to Cloud-Agnostic Offering">​</a></h4>
<p>AWS is our preferred cloud provider due to its extensive services and market dominance. However, we understand that other platforms like Azure and Google Cloud also have strong offerings, and some developers may prefer to consolidate resources with a different provider. While our current focus is on AWS, we acknowledge the potential benefits of a cloud-agnostic approach.</p></article></div></div></main></div><footer class="footer"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Navigation</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/case-study">Case Study</a></li><li class="footer__item"><a class="footer__link-item" href="/team">Team</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/using-cerebellum">Docs</a></li><li class="footer__item"><a href="https://github.com/cerebellum-realtime" target="_blank" rel="noopener noreferrer" class="footer__link-item">Github</a></li></ul></div></div><div class="footer__bottom text--center"><div class="margin-bottom--sm"><a class="footerLogoLink_BH7S" href="/"><img src="/img/logo.png" alt="Cerebellum Logo" class="footer__logo themedComponent_mlkZ themedComponent--light_NVdE" width="100"><img src="/img/logo.png" alt="Cerebellum Logo" class="footer__logo themedComponent_mlkZ themedComponent--dark_xIcU" width="100"></a></div><div class="footer__copyright">Copyright © 2024 Cerebellum</div></div></div></footer></div>
</body>
</html>